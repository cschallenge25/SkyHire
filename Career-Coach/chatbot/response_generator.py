"""
G√©n√©rateur de r√©ponses pour le chatbot Career Coach
Int√®gre l'API Gemini avec un syst√®me de secours FAQ local
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

# Import du client Gemini personnalis√©
from .gemini_client import get_gemini_client

# Configuration du logging
logger = logging.getLogger(__name__)

# Configuration des prompts sp√©cifiques au domaine a√©ronautique
AEROSPACE_PROMPT = """
Tu es un assistant de carri√®re expert dans le secteur a√©ronautique, sp√©cialis√© dans l'accompagnement du personnel navigant (h√¥tesses, stewards, PNC).
Ton r√¥le est de fournir des conseils professionnels pr√©cis et pertinents pour ce secteur sp√©cifique.

Points cl√©s √† respecter :
- Utilise un langage professionnel mais accessible
- Sois pr√©cis sur les certifications et formations (SMURF, MCC, etc.)
- Mentionne les sp√©cificit√©s du m√©tier (d√©calages horaires, conditions de travail, etc.)
- Reste √† jour avec les derni√®res r√©glementations a√©riennes
- Privil√©gie les r√©ponses concr√®tes et actionnables

Si la question sort de ton domaine d'expertise, indique-le clairement.
"""

class ResponseGenerator:
    """Generates responses using Gemini API with FAQ fallback"""
    
    def __init__(self, faq_path: str = None):
        """
        Initialise le g√©n√©rateur de r√©ponses
        
        Args:
            faq_path: Chemin vers le fichier JSON de la FAQ
        """
        self.faq = self._load_faq(faq_path) if faq_path else {}
        self.gemini_client = None
        self._init_gemini()
    
    def _init_gemini(self):
        """Initialise le client Gemini de mani√®re s√©curis√©e"""
        try:
            self.gemini_client = get_gemini_client()
            logger.info("Client Gemini initialis√© avec succ√®s")
        except Exception as e:
            logger.warning(f"Impossible d'initialiser le client Gemini: {e}")
            self.gemini_client = None
    
    def _load_faq(self, faq_path: str) -> Dict:
        """Load FAQ from JSON file with improved path resolution"""
        try:
            # Convertir le chemin en Path object pour une meilleure manipulation
            faq_path = Path(faq_path)
            
            # Si le chemin n'est pas absolu, essayer de le r√©soudre par rapport au r√©pertoire du module
            if not faq_path.is_absolute():
                # Essayer de trouver le fichier dans plusieurs emplacements possibles
                possible_paths = [
                    faq_path,  # Chemin relatif direct
                    Path(__file__).parent / faq_path,  # Par rapport au r√©pertoire du module
                    Path(__file__).parent.parent / faq_path,  # Un niveau au-dessus
                    Path("data") / faq_path,  # Dans le dossier data
                ]
                
                # Essayer chaque chemin jusqu'√† trouver un fichier valide
                for path in possible_paths:
                    if path.exists() and path.is_file():
                        faq_path = path
                        break
                else:
                    # Aucun fichier trouv√©, utiliser le chemin d'origine pour l'erreur
                    raise FileNotFoundError(f"Aucun fichier FAQ trouv√© aux emplacements: {', '.join(str(p) for p in possible_paths)}")
            
            # Charger le fichier
            with open(faq_path, 'r', encoding='utf-8') as f:
                faq_data = json.load(f)
                
            logger.info(f"FAQ charg√©e depuis: {faq_path}")
            return faq_data
            
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de d√©codage du fichier FAQ {faq_path}: {e}")
            return {"intents": {}}
        except Exception as e:
            logger.error(f"Erreur lors du chargement du fichier FAQ {faq_path}: {e}")
            return {"intents": {}}
    
    def _find_in_faq(self, intent: str, user_message: str) -> Optional[Dict]:
        """
        Search for response in FAQ
        
        Args:
            intent: Detected intent
            user_message: User's message for context
            
        Returns:
            Response dict if found, None otherwise
        """
        if not self.faq or "intents" not in self.faq:
            logger.warning("Aucune FAQ charg√©e ou format de FAQ invalide")
            return None
            
        # Normaliser l'intention (supprimer les caract√®res sp√©ciaux et mettre en minuscules)
        normalized_intent = ''.join(c.lower() for c in str(intent) if c.isalnum() or c == '_')
        
        # Essayer de trouver une correspondance exacte avec l'intention normalis√©e
        for faq_intent, data in self.faq.get("intents", {}).items():
            # Normaliser l'intention de la FAQ pour la comparaison
            normalized_faq_intent = ''.join(c.lower() for c in str(faq_intent) if c.isalnum() or c == '_')
            
            # V√©rifier la correspondance exacte avec l'intention normalis√©e
            if normalized_intent == normalized_faq_intent:
                logger.info(f"Correspondance exacte trouv√©e pour l'intention: {intent}")
                return data
        
        # Si aucune correspondance exacte, essayer la correspondance partielle
        for faq_intent, data in self.faq.get("intents", {}).items():
            normalized_faq_intent = ''.join(c.lower() for c in str(faq_intent) if c.isalnum() or c == '_')
            if normalized_faq_intent in normalized_intent or normalized_intent in normalized_faq_intent:
                logger.info(f"Correspondance partielle trouv√©e pour l'intention: {intent} -> {faq_intent}")
                return data
        
        # En dernier recours, essayer la correspondance par mots-cl√©s dans le message
        user_message_lower = user_message.lower()
        for faq_intent, data in self.faq.get("intents", {}).items():
            for keyword in data.get("keywords", []):
                if keyword.lower() in user_message_lower:
                    logger.info(f"Correspondance par mot-cl√© trouv√©e: {keyword} dans le message")
                    return data
                    
        logger.warning(f"Aucune correspondance trouv√©e dans la FAQ pour l'intention: {intent}")
        return None
    
    async def _generate_with_gemini(self, user_message: str, context: Dict) -> Dict:
        """
        Generate response using Gemini API
        
        Args:
            user_message: User's message
            context: Conversation context
            
        Returns:
            Response dictionary
        """
        if not self.gemini_client:
            return {
                "text": "D√©sol√©, le service de g√©n√©ration de r√©ponses n'est pas disponible pour le moment.",
                "suggestions": ["Voir l'aide", "Contacter le support"]
            }
        
        try:
            # Build the prompt with context
            prompt = f"""{AEROSPACE_PROMPT}
            
            Contexte de la conversation:
            - Utilisateur: {context.get('user_id', 'Nouvel utilisateur')}
            - Derni√®re intention d√©tect√©e: {context.get('intent', 'Inconnue')}
            - Historique r√©cent: {context.get('last_messages', [])[-3:]}
            
            Message de l'utilisateur: {user_message}
            
            R√©ponds de mani√®re professionnelle en fran√ßais, en te concentrant sur les aspects carri√®re dans l'a√©rien.
            Si la question concerne un sujet hors de ton domaine, explique-le poliment.
            """
            
            response_text = await self.gemini_client.generate_text(prompt)
            
            return {
                "text": response_text.strip(),
                "source": "gemini",
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            print(f"Error generating response with Gemini: {e}")
            return {
                "text": "Je rencontre des difficult√©s techniques pour g√©n√©rer une r√©ponse. Veuillez r√©essayer plus tard.",
                "source": "error",
                "suggestions": ["R√©essayer", "Contacter le support"]
            }
    
    def _format_response(self, response_data: Dict, intent: str, context: Dict) -> Dict:
        """
        Format the final response with metadata
        
        Args:
            response_data: Raw response data
            intent: Detected intent
            context: Conversation context
            
        Returns:
            Formatted response dictionary
        """
        if not isinstance(response_data, dict):
            response_data = {"text": str(response_data)}
            
        # Add default values if missing
        response_data.setdefault("text", "Je ne suis pas s√ªr de comprendre. Pouvez-vous reformuler ?")
        response_data.setdefault("suggestions", [])
        response_data.setdefault("source", "faq" if "faq" in response_data.get("source", "") else "generated")
        response_data["intent"] = intent
        response_data["timestamp"] = datetime.utcnow().isoformat()
        
        # Add context for debugging
        response_data["_debug"] = {
            "intent": intent,
            "context_keys": list(context.keys()),
            "response_source": response_data["source"]
        }
        
        return response_data
    
    async def generate_response(
        self, 
        user_message: str, 
        intent: str, 
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse au message de l'utilisateur
        
        Args:
            user_message: Le message de l'utilisateur
            intent: L'intention d√©tect√©e
            context: Contexte de conversation optionnel
            
        Returns:
            Dictionnaire contenant la r√©ponse et les m√©tadonn√©es
        """
        # Contexte par d√©faut si non fourni
        context = context or {}
        
        logger.info(f"Tentative de g√©n√©ration de r√©ponse pour l'intention: {intent}")
        
        # D'abord chercher dans la FAQ
        faq_response = self._find_in_faq(intent, user_message)
        if faq_response:
            logger.info(f"‚úÖ R√©ponse trouv√©e dans la FAQ pour l'intention: {intent}")
            return self._format_response(faq_response, intent, context)
        else:
            logger.warning(f"‚ùå Aucune correspondance dans la FAQ pour l'intention: {intent}")
            
        # Si pas de correspondance dans la FAQ et que Gemini est disponible
        if self.gemini_client:
            try:
                logger.info(f"üîç Tentative de g√©n√©ration avec Gemini pour l'intention: {intent}")
                gemini_response = await self._generate_with_gemini(user_message, context)
                if gemini_response and gemini_response.get("text"):
                    logger.info("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s par Gemini")
                    return gemini_response
                else:
                    logger.warning("‚ùå R√©ponse vide de Gemini")
            except Exception as e:
                logger.error(f"‚ùå Erreur avec Gemini: {e}", exc_info=True)
        else:
            logger.warning("üî¥ Client Gemini non disponible")
        
        # R√©ponse de secours
        fallback_responses = [
            "Je n'ai pas pu trouver de r√©ponse appropri√©e dans ma base de connaissances. Pouvez-vous reformuler votre question ou la poser diff√©remment ?",
            "Je ne suis pas s√ªr de bien comprendre votre demande. Pourriez-vous la reformuler ?",
            "Je n'ai pas d'information pr√©cise sur ce sujet. Avez-vous une autre question ?"
        ]
        
        import random
        fallback_text = random.choice(fallback_responses)
        
        logger.warning(f"üîÑ Utilisation d'une r√©ponse de secours pour l'intention: {intent}")
        return self._format_response(
            {
                "text": fallback_text,
                "source": "fallback",
                "suggestions": ["Voir l'aide", "Poser une autre question"]
            },
            intent,
            context
        )

# Example usage
if __name__ == "__main__":
    import asyncio
    from dotenv import load_dotenv
    
    # Load environment variables
    load_dotenv()
    
    async def test_response_generator():
        # Initialize with test FAQ
        faq_path = Path(__file__).parent / "chatbot_faq.json"
        generator = ResponseGenerator(faq_path=str(faq_path))
        
        test_cases = [
            ("Comment r√©diger un bon CV pour une compagnie a√©rienne ?", "CV_Advice"),
            ("Quelles sont les questions d'entretien pour Emirates ?", "Interview_Tips"),
            ("Quel est le salaire moyen d'un PNC ?", "Job_Matching"),
            ("Quelle est la capitale de la France ?", "General_Chat")
        ]
        
        for message, intent in test_cases:
            print(f"\nMessage: {message}")
            print(f"Intent: {intent}")
            
            response = await generator.generate_response(
                user_message=message,
                intent=intent,
                context={"user_id": "test_user"}
            )
            
            print(f"Response: {response['text']}")
            print(f"Source: {response['source']}")
            if response.get('suggestions'):
                print(f"Suggestions: {', '.join(response['suggestions'])}")
            print("-" * 80)
    
    asyncio.run(test_response_generator())